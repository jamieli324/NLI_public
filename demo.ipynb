{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyNofGC7sS9W2aU4OrJucBYU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"53b19a5209114bca86323fac43a3f1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7d48fa7ba8847d2bd386ea9e63b407a","IPY_MODEL_bc9468bd23df41e9a3dc156ef5a59b02","IPY_MODEL_27373606706c47c09c7015eed7fb9fd1"],"layout":"IPY_MODEL_38ca4b7542964a8b8ad19bb225599936"}},"d7d48fa7ba8847d2bd386ea9e63b407a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccb18aaad2604b40aee4b5780cd4a81b","placeholder":"​","style":"IPY_MODEL_9439a98366a2424c8a3e4aa37e20f553","value":"tokenizer_config.json: 100%"}},"bc9468bd23df41e9a3dc156ef5a59b02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af076d5df524441c9679bc5f10c058cc","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5985f91be684350b7751a2ceff174a4","value":25}},"27373606706c47c09c7015eed7fb9fd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b5d981710e840bfba8943883fa226d9","placeholder":"​","style":"IPY_MODEL_ce4247342ce6430e863bd1e1ffc13599","value":" 25.0/25.0 [00:00&lt;00:00, 2.98kB/s]"}},"38ca4b7542964a8b8ad19bb225599936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccb18aaad2604b40aee4b5780cd4a81b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9439a98366a2424c8a3e4aa37e20f553":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af076d5df524441c9679bc5f10c058cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5985f91be684350b7751a2ceff174a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b5d981710e840bfba8943883fa226d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce4247342ce6430e863bd1e1ffc13599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab12f7a6dcff4523b243278d1ae56864":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3daa4bc5ddd4c6ba88fa9f9a5693c35","IPY_MODEL_c766113202da4ed6ab82cd594232142c","IPY_MODEL_ba9e3d9570f945b7beee2f5768f164df"],"layout":"IPY_MODEL_5bf4e100691742d29c139e320864f46c"}},"d3daa4bc5ddd4c6ba88fa9f9a5693c35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7e8dd5a60e348159fa33b94afa8877d","placeholder":"​","style":"IPY_MODEL_149629ac96e54de49679bd3a77aca36c","value":"vocab.json: 100%"}},"c766113202da4ed6ab82cd594232142c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96729f53925543b48a4962e9b0c890cf","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_899b465f45604c71be7e5e727ac7d38b","value":898823}},"ba9e3d9570f945b7beee2f5768f164df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55dbe89557c440498bc2cd1eece4d856","placeholder":"​","style":"IPY_MODEL_6aa2623ada2f4469b19ae9b53a8a5141","value":" 899k/899k [00:00&lt;00:00, 28.2MB/s]"}},"5bf4e100691742d29c139e320864f46c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7e8dd5a60e348159fa33b94afa8877d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"149629ac96e54de49679bd3a77aca36c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96729f53925543b48a4962e9b0c890cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"899b465f45604c71be7e5e727ac7d38b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55dbe89557c440498bc2cd1eece4d856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa2623ada2f4469b19ae9b53a8a5141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f82c850ffb8d4c1086cd676474dd03ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d4afbe9b4804bd689b26ba2db9813ac","IPY_MODEL_602ff0d5e7d84a079e45292a88ec2a5b","IPY_MODEL_5074a29e29604700bf2813e519fadd80"],"layout":"IPY_MODEL_5bedcd29304246169ad9dded453b3eba"}},"0d4afbe9b4804bd689b26ba2db9813ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_556b2fe94f60460892d12bdb02bb3806","placeholder":"​","style":"IPY_MODEL_5ba03c18dd954788bbfa196277bd6fb1","value":"merges.txt: 100%"}},"602ff0d5e7d84a079e45292a88ec2a5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd6421b818ca4994a80dc8f32d6e1faa","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad41e43d685d48c7aa831231b70f83e8","value":456318}},"5074a29e29604700bf2813e519fadd80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f27fd7e004d841b3b9af0267177ebb7f","placeholder":"​","style":"IPY_MODEL_7764a09c035341aba6e962a6a2a191af","value":" 456k/456k [00:00&lt;00:00, 2.12MB/s]"}},"5bedcd29304246169ad9dded453b3eba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"556b2fe94f60460892d12bdb02bb3806":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba03c18dd954788bbfa196277bd6fb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd6421b818ca4994a80dc8f32d6e1faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad41e43d685d48c7aa831231b70f83e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f27fd7e004d841b3b9af0267177ebb7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7764a09c035341aba6e962a6a2a191af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a3f6029314c43c9aaef13f334b04cd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb3cf0d7a62843e5808379c73b802245","IPY_MODEL_f55c3fbe9cc948f19a0f05315cc55479","IPY_MODEL_263b2451a8364883be6aaa76852c6769"],"layout":"IPY_MODEL_e250855679b44e2ea8023c327dc13f21"}},"cb3cf0d7a62843e5808379c73b802245":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b6cb58eea494dd5bc1c8d2ebad223b1","placeholder":"​","style":"IPY_MODEL_1db28034d2364124b571f31c8f6a0240","value":"tokenizer.json: 100%"}},"f55c3fbe9cc948f19a0f05315cc55479":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3203186384714dbdaaa86e84910cdd87","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c98e11e338bf43f58921274e77cbb912","value":1355863}},"263b2451a8364883be6aaa76852c6769":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66da9a5477ae4a7f9009c642efbc36ba","placeholder":"​","style":"IPY_MODEL_73aed0bc9c1547c9a79ba2c7f51ae20b","value":" 1.36M/1.36M [00:00&lt;00:00, 3.20MB/s]"}},"e250855679b44e2ea8023c327dc13f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b6cb58eea494dd5bc1c8d2ebad223b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1db28034d2364124b571f31c8f6a0240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3203186384714dbdaaa86e84910cdd87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c98e11e338bf43f58921274e77cbb912":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66da9a5477ae4a7f9009c642efbc36ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73aed0bc9c1547c9a79ba2c7f51ae20b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aec7b78131745718e4f9479255c34e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cb571810cc84e0c829a3a9a986e905e","IPY_MODEL_dee2c2aa56fe4d13bc53aa76ceb0562f","IPY_MODEL_ab8d819bb5734ab6a7ca4827759a8946"],"layout":"IPY_MODEL_dd822c2896384284b94d34137ab64040"}},"8cb571810cc84e0c829a3a9a986e905e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33f559029cfd49f39beea63d166f4c2f","placeholder":"​","style":"IPY_MODEL_3dd89cb88566482bac82d331643fa624","value":"config.json: 100%"}},"dee2c2aa56fe4d13bc53aa76ceb0562f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfe158bfe5494374a7d9f2b520b5e58e","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d3b34616b9341f59f762223757bd361","value":482}},"ab8d819bb5734ab6a7ca4827759a8946":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a79ded24e3e84a569d965803a553da65","placeholder":"​","style":"IPY_MODEL_9b9ea4f5c99c4d7cb32b6244e32dffd4","value":" 482/482 [00:00&lt;00:00, 63.3kB/s]"}},"dd822c2896384284b94d34137ab64040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f559029cfd49f39beea63d166f4c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dd89cb88566482bac82d331643fa624":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfe158bfe5494374a7d9f2b520b5e58e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d3b34616b9341f59f762223757bd361":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a79ded24e3e84a569d965803a553da65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b9ea4f5c99c4d7cb32b6244e32dffd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2MfmFbdmTNj","executionInfo":{"status":"ok","timestamp":1744302865336,"user_tz":-60,"elapsed":21453,"user":{"displayName":"jamie li","userId":"01375334298802915700"}},"outputId":"92efdda5-721d-480d-b067-391cd19932a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments,RobertaTokenizer,RobertaForSequenceClassification, RobertaModel, RobertaConfig\n","from torch.utils.data import Dataset\n","import torch\n","import pandas as pd\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.metrics import roc_auc_score\n","import pickle"],"metadata":{"id":"zgwWX8i0n-x1","executionInfo":{"status":"ok","timestamp":1744302890761,"user_tz":-60,"elapsed":8850,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Optional: If model won't load from huggingface, this install fixes that"],"metadata":{"id":"pHGdalBHRmpx"}},{"cell_type":"code","source":["!pip install --upgrade \"huggingface_hub[hf_xet]\" transformers"],"metadata":{"id":"jvEG2GFTRmPB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Demo for B"],"metadata":{"id":"CNNsDid5H16b"}},{"cell_type":"code","source":["#load paths and word embeddings\n","train_path = '/content/drive/MyDrive/NLI/train.csv'\n","test_path = \"/content/drive/MyDrive/NLI/test.csv\"\n","glove_path = '/content/drive/MyDrive/NLI/glove.840B.300d.txt'"],"metadata":{"id":"zNp1KVJLmj1O","executionInfo":{"status":"ok","timestamp":1744302897600,"user_tz":-60,"elapsed":9,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\""],"metadata":{"id":"xyftD5k2yctu","executionInfo":{"status":"ok","timestamp":1744302900316,"user_tz":-60,"elapsed":3,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/NLI/vocab_and_glove_new.pkl', 'rb') as f:\n","    word2idx, final_embeddings = pickle.load(f)"],"metadata":{"id":"p7ou9PEUJ0HC","executionInfo":{"status":"ok","timestamp":1744302910757,"user_tz":-60,"elapsed":9347,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#Used code for model from: https://github.com/dunesand/Text-Matching-based-on-ESIM-model/blob/master/esim_model.py\n","# Model proposed is a new model inspired from the ESIM model that got higher accuracies than base ESIM model\n","#Paper: https://arxiv.org/pdf/1609.06038v3"],"metadata":{"id":"pJu32sAKOCxk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ESIM(nn.Module):\n","    def __init__(self, hidden_size, embed_dim, linear_size, embedding_matrix, dropout=0.5):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embed_dim = embed_dim\n","        self.dropout_rate = dropout\n","\n","        #embedding layer with embedding matrix created.\n","        num_words = embedding_matrix.shape[0] - 1\n","        self.embedding = nn.Embedding(num_words + 1, embed_dim, padding_idx=0)\n","        self.embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float(), requires_grad=True)\n","        self.embed_dropout = nn.Dropout(dropout)\n","        self.bn_embedding = nn.BatchNorm1d(embed_dim)\n","\n","        #biLSTM encoder\n","        self.lstm1 = nn.LSTM(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n","\n","        #contextual encoding enhanced using self-attention\n","        self.self_attention = nn.MultiheadAttention(embed_dim=2 * hidden_size, num_heads=4, batch_first=True)\n","\n","        #2 layer biLSTM used with dropout for regularisation\n","        self.lstm2 = nn.LSTM(hidden_size * 8, hidden_size, num_layers=2, batch_first=True,\n","                             bidirectional=True, dropout=dropout)\n","        # projection to match dimensions input is 8*hidden_size, output is 2*hidden_size.\n","        self.residual_proj = nn.Linear(hidden_size * 8, 2 * hidden_size)\n","\n","        #gating layer is used to modulate the new representations\n","        self.attention_gate = nn.Linear(2 * hidden_size, 2 * hidden_size)\n","\n","        #final classifier that takes [o1_rep, o2_rep, diff, prod] (16*hidden_size).\n","        self.classifier = nn.Sequential(\n","            nn.BatchNorm1d(16 * hidden_size),\n","            nn.Linear(16 * hidden_size, linear_size),\n","            nn.ELU(inplace=True),\n","            nn.BatchNorm1d(linear_size),\n","            nn.Dropout(dropout),\n","            nn.Linear(linear_size, linear_size),\n","            nn.ELU(inplace=True),\n","            nn.BatchNorm1d(linear_size),\n","            nn.Dropout(dropout),\n","            nn.Linear(linear_size, 1)\n","        )\n","\n","        #mask value\n","        self.mask_val = -2**32 + 1.0\n","\n","    def forward(self, sent1, sent2):\n","        #masks where tokens = 0\n","        mask1 = sent1.eq(0)\n","        mask2 = sent2.eq(0)\n","\n","        #embedding shape = (batch, seq_len, embed_dim), dropout, and batch normalisation.\n","        x1 = self.embed_dropout(self.embedding(sent1))\n","        x2 = self.embed_dropout(self.embedding(sent2))\n","        x1 = self.bn_embedding(x1.transpose(1, 2)).transpose(1, 2)\n","        x2 = self.bn_embedding(x2.transpose(1, 2)).transpose(1, 2)\n","\n","        #first biLSTM encoding with shape = (batch, seq_len, 2*hidden_size)\n","        o1, _ = self.lstm1(x1)\n","        o2, _ = self.lstm1(x2)\n","\n","        #self-attention is applied\n","        o1_sa, _ = self.self_attention(o1, o1, o1)\n","        o2_sa, _ = self.self_attention(o2, o2, o2)\n","        o1 = o1 + o1_sa\n","        o2 = o2 + o2_sa\n","\n","        #soft-attention alignments\n","        o1_aligned, o2_aligned = self.soft_attention_align(o1, o2, mask1, mask2)\n","\n","        #gating applied\n","        gate1 = torch.sigmoid(self.attention_gate(o1))\n","        gate2 = torch.sigmoid(self.attention_gate(o2))\n","        o1_aligned = o1_aligned * gate1\n","        o2_aligned = o2_aligned * gate2\n","\n","        #original and aligned representation concatenated with element-wise subtractions and multiplication\n","        o1_combined = torch.cat([o1, o1_aligned, self.submul(o1, o1_aligned)], dim=-1)\n","        o2_combined = torch.cat([o2, o2_aligned, self.submul(o2, o2_aligned)], dim=-1)\n","\n","        #representations using the deeper LSTM\n","        o1_composed, _ = self.lstm2(o1_combined)\n","        #residual connections used to preserve lower level features\n","        o1_composed = o1_composed + self.residual_proj(o1_combined)\n","\n","        o2_composed, _ = self.lstm2(o2_combined)\n","        o2_composed = o2_composed + self.residual_proj(o2_combined)\n","\n","        #pooling on the aggregate representations, both with shape = (batch, 4*hidden_size)\n","        o1_rep = self.apply_pooling(o1_composed)\n","        o2_rep = self.apply_pooling(o2_composed)\n","\n","        #absolute difference and element-wise features captured for additional pair features\n","        diff = torch.abs(o1_rep - o2_rep)\n","        prod = o1_rep * o2_rep\n","\n","        #features concatenated with shape = (batch, 16*hidden_size)\n","        combined_rep = torch.cat([o1_rep, o2_rep, diff, prod], dim=-1)\n","\n","        # Final classification.\n","        similarity = self.classifier(combined_rep)\n","        return similarity\n","\n","    def soft_attention_align(self, x1, x2, mask1, mask2):\n","        #attention scores computed\n","        attention_scores = torch.matmul(x1, x2.transpose(1, 2))\n","\n","        #masks then applied to attention scores\n","        mask1_val = mask1.float().masked_fill(mask1, self.mask_val)\n","        mask2_val = mask2.float().masked_fill(mask2, self.mask_val)\n","\n","        #compute soft alignment weights and produce aligned representations.\n","        weight1 = F.softmax(attention_scores + mask2_val.unsqueeze(1), dim=-1)\n","        aligned_x1 = torch.matmul(weight1, x2)\n","        weight2 = F.softmax(attention_scores.transpose(1, 2) + mask1_val.unsqueeze(1), dim=-1)\n","        aligned_x2 = torch.matmul(weight2, x1)\n","        return aligned_x1, aligned_x2\n","\n","    def submul(self, x1, x2):\n","        #element-wise subtractions and multiplication\n","        subtraction = x1 - x2\n","        multiplication = x1 * x2\n","        return torch.cat([subtraction, multiplication], dim=-1)\n","\n","    def apply_pooling(self, x):\n","        #average and max pooling\n","        avg_pooled = F.avg_pool1d(x.transpose(1, 2), kernel_size=x.size(1)).squeeze(-1)\n","        max_pooled = F.max_pool1d(x.transpose(1, 2), kernel_size=x.size(1)).squeeze(-1)\n","        return torch.cat([avg_pooled, max_pooled], dim=-1)\n"],"metadata":{"id":"lRuFYjHZN8zI","executionInfo":{"status":"ok","timestamp":1744302914078,"user_tz":-60,"elapsed":21,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#dataset reads the csv from filepath and returns the tokenised, indexed tensors of sentence pairs with the label\n","class NliDataset(Dataset):\n","    def __init__(self, filepath, word2idx, max_len=64):\n","        self.data = pd.read_csv(filepath)\n","        self.word2idx = word2idx\n","        self.max_len = max_len\n","\n","    def encode(self, sentence):\n","        tokens = sentence.lower().split()\n","        ids = [self.word2idx.get(tok, self.word2idx['<unk>']) for tok in tokens]\n","        return torch.tensor(ids[:self.max_len], dtype=torch.long)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        sent1 = self.encode(row['premise'])\n","        sent2 = self.encode(row['hypothesis'])\n","        return sent1, sent2\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","def collate_fn(batch):\n","    #combines multiple samples into a batch, padding applied for consistent lengths\n","    s1, s2 = zip(*batch)\n","    s1 = pad_sequence(s1, batch_first=True, padding_value=0)\n","    s2 = pad_sequence(s2, batch_first=True, padding_value=0)\n","    return s1, s2"],"metadata":{"id":"XH56BVJ_wXL1","executionInfo":{"status":"ok","timestamp":1744302922420,"user_tz":-60,"elapsed":48,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Model loaded from path and set to evaluation mode, the test data loaded too"],"metadata":{"id":"ck1yX3pJIBVE"}},{"cell_type":"code","source":["model = ESIM(hidden_size=300, embed_dim=300, linear_size=512, embedding_matrix=final_embeddings)\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLI/best_model_esim_improved_new_T_good.pt\"))\n","model.to(device)\n","model.eval()\n","test_dataset = NliDataset(test_path, word2idx)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"],"metadata":{"id":"PFFS8hHKJmYf","executionInfo":{"status":"ok","timestamp":1744302963251,"user_tz":-60,"elapsed":5589,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def predict_on_dev(model, test_loader, device):\n","    model.eval()\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for sent1, sent2 in test_loader:\n","            sent1, sent2 = sent1.to(device), sent2.to(device)\n","\n","            logits = model(sent1, sent2)\n","            logits = logits.squeeze(-1)\n","            probs = torch.sigmoid(logits)\n","            preds = (probs >= 0.5).long()\n","\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    return all_preds"],"metadata":{"id":"V2Xpmpr0J1uW","executionInfo":{"status":"ok","timestamp":1744302976582,"user_tz":-60,"elapsed":24,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test_preds = predict_on_dev(model, test_loader, device)\n","\n","pred_df = pd.DataFrame({\"prediction\": test_preds})\n","\n","pred_df.to_csv(\"/content/drive/MyDrive/NLI/test_predictions_B_new.csv\", index=False)\n","print(\"Saved predictions to test_predictions_B.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYhm9-cKJ9Ms","executionInfo":{"status":"ok","timestamp":1744302979680,"user_tz":-60,"elapsed":1757,"user":{"displayName":"jamie li","userId":"01375334298802915700"}},"outputId":"195a8381-218b-4bb0-e29e-9e1a42e38628"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved predictions to test_predictions_B.csv\n"]}]},{"cell_type":"markdown","source":["## Demo for C"],"metadata":{"id":"6AzL3oigINdu"}},{"cell_type":"code","source":["tokeniser = RobertaTokenizer.from_pretrained(\"roberta-large\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["53b19a5209114bca86323fac43a3f1f7","d7d48fa7ba8847d2bd386ea9e63b407a","bc9468bd23df41e9a3dc156ef5a59b02","27373606706c47c09c7015eed7fb9fd1","38ca4b7542964a8b8ad19bb225599936","ccb18aaad2604b40aee4b5780cd4a81b","9439a98366a2424c8a3e4aa37e20f553","af076d5df524441c9679bc5f10c058cc","c5985f91be684350b7751a2ceff174a4","6b5d981710e840bfba8943883fa226d9","ce4247342ce6430e863bd1e1ffc13599","ab12f7a6dcff4523b243278d1ae56864","d3daa4bc5ddd4c6ba88fa9f9a5693c35","c766113202da4ed6ab82cd594232142c","ba9e3d9570f945b7beee2f5768f164df","5bf4e100691742d29c139e320864f46c","e7e8dd5a60e348159fa33b94afa8877d","149629ac96e54de49679bd3a77aca36c","96729f53925543b48a4962e9b0c890cf","899b465f45604c71be7e5e727ac7d38b","55dbe89557c440498bc2cd1eece4d856","6aa2623ada2f4469b19ae9b53a8a5141","f82c850ffb8d4c1086cd676474dd03ef","0d4afbe9b4804bd689b26ba2db9813ac","602ff0d5e7d84a079e45292a88ec2a5b","5074a29e29604700bf2813e519fadd80","5bedcd29304246169ad9dded453b3eba","556b2fe94f60460892d12bdb02bb3806","5ba03c18dd954788bbfa196277bd6fb1","cd6421b818ca4994a80dc8f32d6e1faa","ad41e43d685d48c7aa831231b70f83e8","f27fd7e004d841b3b9af0267177ebb7f","7764a09c035341aba6e962a6a2a191af","3a3f6029314c43c9aaef13f334b04cd3","cb3cf0d7a62843e5808379c73b802245","f55c3fbe9cc948f19a0f05315cc55479","263b2451a8364883be6aaa76852c6769","e250855679b44e2ea8023c327dc13f21","8b6cb58eea494dd5bc1c8d2ebad223b1","1db28034d2364124b571f31c8f6a0240","3203186384714dbdaaa86e84910cdd87","c98e11e338bf43f58921274e77cbb912","66da9a5477ae4a7f9009c642efbc36ba","73aed0bc9c1547c9a79ba2c7f51ae20b","2aec7b78131745718e4f9479255c34e3","8cb571810cc84e0c829a3a9a986e905e","dee2c2aa56fe4d13bc53aa76ceb0562f","ab8d819bb5734ab6a7ca4827759a8946","dd822c2896384284b94d34137ab64040","33f559029cfd49f39beea63d166f4c2f","3dd89cb88566482bac82d331643fa624","bfe158bfe5494374a7d9f2b520b5e58e","3d3b34616b9341f59f762223757bd361","a79ded24e3e84a569d965803a553da65","9b9ea4f5c99c4d7cb32b6244e32dffd4"]},"id":"n0iN9w6gAW0a","executionInfo":{"status":"ok","timestamp":1744291423707,"user_tz":-60,"elapsed":4733,"user":{"displayName":"jamie li","userId":"01375334298802915700"}},"outputId":"280e2577-2103-4301-f213-ef5fe1be99ec"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b19a5209114bca86323fac43a3f1f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab12f7a6dcff4523b243278d1ae56864"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82c850ffb8d4c1086cd676474dd03ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a3f6029314c43c9aaef13f334b04cd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aec7b78131745718e4f9479255c34e3"}},"metadata":{}}]},{"cell_type":"code","source":["class ExplainableModel(nn.Module):\n","    #RoBERTa used to encode input sequences\n","    #span-based features using SIC obtained\n","    #interpretation used to weight the spans and generates explainable summary\n","    #prediction is a combination of most relevant spans\n","    def __init__(self, bert_dir):\n","        super().__init__()\n","        self.bert_config = RobertaConfig.from_pretrained(bert_dir, num_labels=2)\n","        self.intermediate = RobertaModel.from_pretrained(bert_dir)\n","        self.span_info_collect = SICModel(self.bert_config.hidden_size)\n","        self.interpretation = InterpretationModel(self.bert_config.hidden_size)\n","        self.output = nn.Linear(self.bert_config.hidden_size, 1)\n","\n","    def forward(self, input_ids, start_indexs, end_indexs, span_masks):\n","        # generate mask\n","        attention_mask = (input_ids != 1).long()\n","        # intermediate layer\n","        hidden_states = self.intermediate(input_ids, attention_mask=attention_mask).last_hidden_state\n","        # span info collecting layer(SIC)\n","        h_ij = self.span_info_collect(hidden_states, start_indexs, end_indexs)\n","        # interpretation layer\n","        H, a_ij = self.interpretation(h_ij, span_masks)\n","        # output layer\n","        out = self.output(H)\n","        return out, a_ij\n","\n","\n","class SICModel(nn.Module):\n","    def __init__(self, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        #linear transformations for different span endpoints\n","        self.W_1 = nn.Linear(hidden_size, hidden_size) #start token\n","        self.W_2 = nn.Linear(hidden_size, hidden_size) #end token\n","        self.W_3 = nn.Linear(hidden_size, hidden_size) #start and end difference\n","        self.W_4 = nn.Linear(hidden_size, hidden_size) #start and end interaction\n","\n","    def forward(self, hidden_states, start_indexs, end_indexs):\n","        # hidden_states: (batch_size, seq_len, hidden_size)\n","        # start_indexs / end_indexs: (batch_size, span_len)\n","\n","        batch_size, seq_len, hidden_size = hidden_states.size()\n","        span_len = start_indexs.size(1)\n","\n","        #transformations applied in batch\n","        W1_h = self.W_1(hidden_states)\n","        W2_h = self.W_2(hidden_states)\n","        W3_h = self.W_3(hidden_states)\n","        W4_h = self.W_4(hidden_states)\n","\n","        #transformed embeddings collected for each span\n","        W1_hi_emb = [] #collect transformed start token embeddings\n","        W2_hj_emb = [] #collect transformed end token embeddings\n","        W3_hi_start_emb = [] #(h_i - h_j)\n","        W3_hi_end_emb = []\n","        W4_hj_start_emb = [] #(h_i * h_j)\n","        W4_hj_end_emb = []\n","\n","        #iterate through each item in batch, select transformed hidden states\n","        #at span positions, this collects span representations per example\n","        for b in range(batch_size):\n","            si = start_indexs[b]\n","            ei = end_indexs[b]\n","\n","            W1_hi_emb.append(W1_h[b].index_select(0, si))\n","            W2_hj_emb.append(W2_h[b].index_select(0, ei))\n","            W3_hi_start_emb.append(W3_h[b].index_select(0, si))\n","            W3_hi_end_emb.append(W3_h[b].index_select(0, ei))\n","            W4_hj_start_emb.append(W4_h[b].index_select(0, si))\n","            W4_hj_end_emb.append(W4_h[b].index_select(0, ei))\n","\n","        #embeddings now stacked to give tensor shape = (batch_size, span_len, hidden_size)\n","        W1_hi_emb = torch.stack(W1_hi_emb)\n","        W2_hj_emb = torch.stack(W2_hj_emb)\n","        W3_hi_start_emb = torch.stack(W3_hi_start_emb)\n","        W3_hi_end_emb = torch.stack(W3_hi_end_emb)\n","        W4_hj_start_emb = torch.stack(W4_hj_start_emb)\n","        W4_hj_end_emb = torch.stack(W4_hj_end_emb)\n","\n","        #combine span representations\n","        span = (\n","            W1_hi_emb +\n","            W2_hj_emb +\n","            (W3_hi_start_emb - W3_hi_end_emb) +\n","            torch.mul(W4_hj_start_emb, W4_hj_end_emb)\n","        )\n","\n","        h_ij = torch.tanh(span)\n","        return h_ij\n","\n","class InterpretationModel(nn.Module):\n","    #assign importance weights for each span\n","    #linear scoring layer for all span representations\n","    #span masks used to mask illegal spans\n","    #softmax to normalise attention weights\n","    #weighted average of spans gives final sentence representation (H)\n","    def __init__(self, hidden_size):\n","        super().__init__()\n","        self.h_t = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, h_ij, span_masks):\n","        o_ij = self.h_t(h_ij).squeeze(-1)  # (ba, span_num)\n","        # mask illegal span\n","        o_ij = o_ij - span_masks\n","        # normalize all a_ij, a_ij sum = 1\n","        a_ij = nn.functional.softmax(o_ij, dim=1)\n","        # weight average span representation to get H\n","        H = (a_ij.unsqueeze(-1) * h_ij).sum(dim=1)  # (bs, hidden_size)\n","        return H, a_ij\n"],"metadata":{"id":"bqkK3avA_N2y","executionInfo":{"status":"ok","timestamp":1744291425152,"user_tz":-60,"elapsed":43,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class NliDataset(Dataset):\n","    def __init__(self, csv_path):\n","        self.df = pd.read_csv(csv_path)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        return {\n","            \"premise\": str(row[\"premise\"]),\n","            \"hypothesis\": str(row[\"hypothesis\"])\n","        }"],"metadata":{"id":"TetjXYS9_PPq","executionInfo":{"status":"ok","timestamp":1744291430975,"user_tz":-60,"elapsed":2,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def collate(batch):\n","    input_ids_list = []\n","    start_idxs = []\n","    end_idxs = []\n","    span_masks = []\n","    max_len = 512\n","\n","    #each example in the batch is looped through\n","    for item in batch:\n","        #premise and hypothesis are tokenised, also padded to the max length and truncated if greater than the max length\n","        enc =tokeniser(\n","            item[\"premise\"],\n","            item[\"hypothesis\"],\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=max_len\n","\n","        )\n","\n","        input_ids = enc[\"input_ids\"].squeeze(0)\n","\n","        #length without padding is calculated\n","        token_len = (input_ids != tokeniser.pad_token_id).sum().item()\n","\n","        #generate all possible spans of length 1: (i, i+1) for valid token positions\n","        span_start = torch.arange(1, token_len - 2)\n","        span_end = span_start + 1\n","        span_mask = torch.zeros_like(span_start).float()\n","\n","        #pad span index and masks so they're the same length\n","        input_ids_list.append(input_ids)\n","        start_idxs.append(span_start)\n","        end_idxs.append(span_end)\n","        span_masks.append(span_mask)\n","\n","    start_idxs = pad_sequence(start_idxs, batch_first=True)\n","    end_idxs = pad_sequence(end_idxs, batch_first=True)\n","    span_masks = pad_sequence(span_masks, batch_first=True)\n","\n","    #return tokenised inputs, span start/end indexes, span masks and labels\n","    return(\n","        torch.stack(input_ids_list),\n","        start_idxs,\n","        end_idxs,\n","        span_masks\n","    )"],"metadata":{"id":"E0W7Yoz5AJw5","executionInfo":{"status":"ok","timestamp":1744291434312,"user_tz":-60,"elapsed":17,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Load transformer model and fresh testset"],"metadata":{"id":"T5qsRu_bRcGA"}},{"cell_type":"code","source":["model = ExplainableModel(\"roberta-large\").to(device)\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLI/best_model_Transformer_Large_new.pt\"))\n","model.to(device)\n","model.eval()\n","test_dataset = NliDataset(test_path)\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UoYfFgDO_cgz","executionInfo":{"status":"ok","timestamp":1744291495127,"user_tz":-60,"elapsed":26005,"user":{"displayName":"jamie li","userId":"01375334298802915700"}},"outputId":"84be5c97-f6a8-4cc3-85d7-96b7b4727632"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def predict_on_dev_C(model, dev_loader, device):\n","    model.eval()\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for input_ids, start_idxs, end_idxs, span_masks in dev_loader:\n","\n","            input_ids = input_ids.to(device)\n","            start_idxs = start_idxs.to(device)\n","            end_idxs = end_idxs.to(device)\n","            span_masks = span_masks.to(device)\n","\n","            logits, _ = model(input_ids, start_idxs, end_idxs, span_masks)\n","            probs = torch.sigmoid(logits).squeeze(-1)\n","\n","            preds = (probs >= 0.5).long()\n","\n","            all_preds.extend(preds.cpu().tolist())\n","\n","    return all_preds\n"],"metadata":{"id":"Hfez0wpzArs4","executionInfo":{"status":"ok","timestamp":1744291504737,"user_tz":-60,"elapsed":40,"user":{"displayName":"jamie li","userId":"01375334298802915700"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test_preds = predict_on_dev_C(model, test_loader, device)\n","\n","pred_df = pd.DataFrame({\"prediction\": test_preds})\n","\n","pred_df.to_csv(\"/content/drive/MyDrive/NLI/test_predictions_C.csv\", index=False)\n","print(\"Saved predictions to test_predictions_C.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GwsaC7LAR_1","executionInfo":{"status":"ok","timestamp":1744291640872,"user_tz":-60,"elapsed":129436,"user":{"displayName":"jamie li","userId":"01375334298802915700"}},"outputId":"f399606e-4e3d-461e-870e-30ed781ff56b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved predictions to test_predictions_C.csv\n"]}]}]}